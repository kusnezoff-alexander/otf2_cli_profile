---
title: "I/O Summary of <>"
execute:
  echo: false
---

```{ojs}
// === Helper Functions

// attached files need to be in same dir !
results = FileAttachment("results.json").json({ typed: true })

ticks_per_second = results.TimerResolution

// Function to format axis labels
function formatBytesAxis(bytes) {
  if (bytes >= 1e15) return (bytes / 1e15).toFixed(2) + " PB";
  if (bytes >= 1e12) return (bytes / 1e12).toFixed(2) + " TB";
  if (bytes >= 1e9)  return (bytes / 1e9).toFixed(2) + " GB";
  if (bytes >= 1e6)  return (bytes / 1e6).toFixed(2) + " MB";
  if (bytes >= 1e3)  return (bytes / 1e3).toFixed(2) + " KB";
  return bytes + " B";
}

function formatTimeAxis(seconds) {
  if (seconds >= 3600) return (seconds / 3600).toFixed(2) + " h";
  if (seconds >= 60)   return (seconds / 60).toFixed(2) + " min";
  if (seconds >= 1)    return seconds.toFixed(2) + " s";
  if (seconds >= 1e-3) return (seconds * 1e3).toFixed(2) + " ms";
  if (seconds >= 1e-6) return (seconds * 1e6).toFixed(2) + " Âµs";
  return (seconds * 1e9).toFixed(2) + " ns";
}

```

```{ojs}
// === Styling
html`<style>
  figcaption {
    font-size: clamp(0.5vw, 0.5em, 2vw);
    font-style: italic; /* often captions are italic */
    color: #666;
    margin-top: 6px;
  }
</style>`
```

## By paradigm

```{ojs}

// Extract IOOperations
ioData = Object.entries(results.IOOperations).map(([paradigm, ops]) => ({
	paradigm,
	bytes: ops.Bytes,
	meta: ops.MetaOperationTime / ticks_per_second,
	transfer: ops.TransferOperationTime / ticks_per_second,
	count: ops.Count
}));

// Create charts
chartBytes = Plot.plot({
	caption: "(a) I/O size per I/O Paradigm",
	marks: [Plot.barY(ioData, {x: "paradigm", y: "bytes", fill: "paradigm"})],
	y: {label: "Bytes", tickFormat: formatBytesAxis},
	width: 400,
	height: 300
});

chartTransfer = Plot.plot({
	caption: "(b) I/O time per I/O Paradigm",
	marginLeft: 70,
	marks: [Plot.barY(ioData, {x: "paradigm", y: "transfer", fill: "paradigm"})],
	y: {label: "I/O Operation Time", tickFormat: formatTimeAxis},
	width: 400,
	height: 300
});

chartMeta = Plot.plot({
	caption: "(c) Meta I/O time per I/O Paradigm",
	marginLeft: 70,
	marks: [Plot.barY(ioData, {x: "paradigm", y: "meta", fill: "paradigm"})],
	y: {label: "Meta I/O Operation Time", tickFormat: formatTimeAxis},
	width: 400,
	height: 300
});

// Return horizontal container
html`<div style="display:flex; gap:20px;">${chartBytes}${chartTransfer}${chartMeta}</div>`
```

## By Access Pattern

### Local Access Pattern

```{ojs}
// Aggregate ticks and bytes per access pattern safely
// Aggregate using reduce
accessPatternData = results.Files.reduce((acc, file) => {
	const ticks = file["Ticks spent per Access Pattern"] || {};
	const ioSizes = file["I/O sizes per Access Pattern"] || {};

	Object.entries(ticks).forEach(([pattern, val]) => {
	if (!(pattern in acc)) acc[pattern] = {ticks: 0, bytes: 0};
		acc[pattern].ticks += val;
		acc[pattern].bytes += ioSizes[pattern] || 0;
	});

	return acc;
}, {});

// Convert to array for plotting
accessPatternArray = Object.entries(accessPatternData).map(([pattern, val]) => ({
	pattern,
	ticks: val.ticks,
	bytes: val.bytes
}));

// Strip prefix from pattern labels
_ = accessPatternArray.forEach(d => {
	d.pattern = d.pattern.replace(/^AccessPattern::/, "");
});
```

```{ojs}
function dualAxisY(data, {y, ticks = 10, tickFormat, ...options} = {}) {
  const [y1, y2] = d3.extent(Plot.valueof(data, y));
  const scale = d3.scaleLinear().domain([y1, y2]);
  return Plot.axisY(d3.ticks(y1, y2, ticks), {
    ...options,
    y: scale,
    tickFormat
  });
}

// Prepare data
leftColor = "#4e79a7";
left = Object.entries(accessPatternData).map(([pattern, val]) => ({
  pattern: pattern.replace(/^AccessPattern::/, ""),
  ticks: val.ticks / ticks_per_second,
}));
rightColor = "#f28e2c";
right = Object.entries(accessPatternData).map(([pattern, val]) => ({
  pattern: pattern.replace(/^AccessPattern::/, ""),
  bytes: val.bytes
}));

// Plot with formatted bytes axis
Plot.plot({
  caption: "Fig.2 I/O Request Sizes and I/O Time by Access Pattern",
  marginLeft: 70,
  color: {legend: true},
  marks: [
    dualAxisY(left, {
      y: "ticks",
      anchor: "left",
      color: leftColor,
      label: "Ticks",
	  tickFormat: formatTimeAxis
    }),
    dualAxisY(right, {
      y: "bytes",
      anchor: "right",
      color: rightColor,
      label: "Bytes",
      tickFormat: formatBytesAxis
    }),
    Plot.barY(left, Plot.normalizeY("extent", {
      x: "pattern",
      y: "ticks",
      dx: -20,
      insetLeft: 40,
      insetRight: 40,
      fill: leftColor
    })),
    Plot.barY(right, Plot.normalizeY("extent", {
      x: "pattern",
      y: "bytes",
      dx: 20,
      insetLeft: 40,
      insetRight: 40,
      fill: rightColor
    }))
  ]
})

```

### Global Access Pattern

TODO

## Files

```{ojs}
// Helper Functions
function commonPrefix(strings) {
  if (!strings.length) return "";
  let prefix = strings[0];
  for (let str of strings.slice(1)) {
    let i = 0;
    while (i < prefix.length && prefix[i] === str[i]) i++;
    prefix = prefix.slice(0, i);
    if (!prefix) break;
  }
  return prefix;
}

function getBasePath(path) {
  // Return everything before the last slash
  const lastSlash = path.lastIndexOf("/");
  return lastSlash !== -1 ? path.slice(0, lastSlash + 1) : "";
}

```

Top 10 by read size:
```{ojs}
topReadFiles = results.Files
  .filter(f => f["#Bytes read"] > 0) // Ignore entries with 0 read bytes
  .sort((a, b) => b["#Bytes read"] - a["#Bytes read"]) // Sort descending
  .slice(0, 10) // Top 10

// filter common path prefix
common_read = topReadFiles.length > 1
  ? commonPrefix(topReadFiles.map(f => f.FileName))
  : getBasePath(topReadFiles[0]?.FileName ?? "");

Inputs.table(
  topReadFiles.map(f => ({
    FileName: f.FileName.replace(common_read, ""),
    "#Bytes read": f["#Bytes read"],
    "#Bytes write": f["#Bytes write"],
    "Ticks spent": f["Ticks spent"]
  }))
)
```

Top 10 by write size:
```{ojs}
topWriteFiles = results.Files
  .filter(f => f["#Bytes write"] > 0) // Ignore entries with 0 read bytes
  .sort((a, b) => b["#Bytes write"] - a["#Bytes write"]) // Sort descending
  .slice(0, 10) // Top 10

// filter common path prefix
common_write = topWriteFiles.length > 1
  ? commonPrefix(topWriteFiles.map(f => f.FileName))
  : getBasePath(topReadFiles[0]?.FileName ?? "");

Inputs.table(
  topWriteFiles.map(f => ({
    FileName: f.FileName.replace(common_write, ""),
    "#Bytes read": f["#Bytes read"],
    "#Bytes write": f["#Bytes write"],
    "Ticks spent": f["Ticks spent"]
  }))
)

```

Top 10 by I/O time:
```{ojs}
topIOFiles = results.Files
  .filter(f => f["Ticks spent"] > 0) // Ignore entries with 0 read bytes
  .sort((a, b) => b["Ticks spent"] - a["Ticks spent"]) // Sort descending
  .slice(0, 10) // Top 10

// filter common path prefix
common_io = topIOFiles.length > 1
  ? commonPrefix(topIOFiles.map(f => f.FileName))
  : getBasePath(topReadFiles[0]?.FileName ?? "");

Inputs.table(
  topIOFiles.map(f => ({
    FileName: f.FileName.replace(common_io, ""),
    "#Bytes read": f["#Bytes read"],
    "#Bytes write": f["#Bytes write"],
    "Ticks spent": f["Ticks spent"]
  }))
)
```

## AI Summary

<!--
TODO: LLM-Generated Analysis of the following plots? (just mentioning some strange things it noticed?)

Used Prompt:
```
Pls analyze this pdf which contains diagrams summarizing its I/O behavior. Answer each of the following questions:

Which I/O paradigm is used the most?
Which Access Pattern is the most dominant one?
Which files are being operated on the most?
What should an I/O Performance Engineer look into more after seeing this summary? Especially highlight potential bottlenecks
The answer is expected to be in the following format:
1. **I/O Paradigms**: <Your Answer>
2. **Acces Patterns**: <Your Answer>
3. **Files**: <Your Answer>
4. **General Advice**: <Your Answer>

Please don't respond with more than 3-4 sentences per question
```
-->

\[HARDCODED LLM Analysis (using Claude Sonnet 4.5\]

**I/O Paradigms**: Based on the visualizations, both ISO C I/O and POSIX I/O appear to be used relatively equally, with similar distributions in I/O sizes and operation times. Neither paradigm shows clear dominance in terms of usage volume. The similar box plot distributions suggest balanced usage across both paradigms in this workload.

**Access Patterns**: The data shows activity across all four patterns (CONTIGUOUS_EQUALLY_SIZED, NONE, RANDOM_EQUALLY_SIZED, and STRIDED_EQUALLY_SIZED), but without clear numerical values, it's difficult to definitively identify the most dominant one. However, the three named files (contiguous.txt, random.txt, strided.txt) suggest that structured patterns (contiguous, random, and strided) are all significantly active. The "NONE" pattern appears to have less activity based on the visual representation.

**Files**: The top files being operated on are random.txt (highest I/O time and significant write activity), contiguous.txt (top write size and high I/O time), and strided.txt (top read size and notable I/O time). These three files dominate across all metrics - read size, write size, and time spent - making them the primary targets for I/O operations in this workload.

**General Advice**: The I/O Performance Engineer should prioritize investigating random.txt as it appears in both top write operations and top I/O time, suggesting random access patterns are creating a bottleneck. The engineer should analyze whether random access can be converted to more sequential patterns or if caching strategies can reduce the performance impact. Additionally, they should examine why strided.txt has high read activity and whether prefetching or buffer optimization could improve performance, and evaluate if the heavy write operations to contiguous.txt can benefit from larger buffer sizes or asynchronous I/O.
